{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seelisher/ISYS5002_Yixiao-Li_20526379_Homework/blob/main/08_working_with_web.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download File/Data from the Web"
      ],
      "metadata": {
        "id": "71EBZxXa0QCH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using `urllib`\n",
        "https://realpython.com/urllib-request/\n",
        "\n",
        "The docs [urllib.request.urlretrieve](https://docs.python.org/3/library/urllib.request.html#urllib.request.urlretrieve) state:\n",
        "\n",
        "> The following functions and classes are ported from the Python 2 module urllib (as opposed to urllib2). They might become deprecated at some point in the future.\n",
        "\n"
      ],
      "metadata": {
        "id": "u3YsZa9ymQ1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib \n",
        "from urllib import request\n",
        "urllib.request.urlretrieve('https://en.wikipedia.org/wiki/Python_(programming_language)', \"myFileURL.txt\")\n"
      ],
      "metadata": {
        "id": "ikCr3g3hmRVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using `requests`\n",
        "\n",
        "https://www.w3schools.com/python/module_requests.asp\n",
        "\n",
        "https://www.geeksforgeeks.org/downloading-files-web-using-python/\n"
      ],
      "metadata": {
        "id": "NCzwu5WljFZD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buijFrayZdi3"
      },
      "outputs": [],
      "source": [
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the requests library\n",
        "import requests\n",
        "\n",
        "site_url = \"https://en.wikipedia.org/wiki/Python_(programming_language)\"\n",
        "\n",
        "# sending get request and saving the response as response object\n",
        "response = requests.get(site_url) #use the get method to request a webpage/data from server\n",
        "\n",
        "# print content of response\n",
        "print(response.content)\n",
        "\n",
        "with open('myFileRequests.txt', 'wb') as file: # 'wb' because response stored as bytes\n",
        "  file.write(response.content)\n"
      ],
      "metadata": {
        "id": "7EZMZNN3ModC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using `wget`"
      ],
      "metadata": {
        "id": "IOVfYPGIjRHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#download a pdf file\n",
        "!wget https://link.springer.com/content/pdf/10.1007/s11306-019-1588-0.pdf "
      ],
      "metadata": {
        "id": "EflZbP3y2eZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download a webpage\n",
        "!wget \"https://en.wikipedia.org/wiki/Python_(programming_language)\""
      ],
      "metadata": {
        "id": "s7s8L1_Zje8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget"
      ],
      "metadata": {
        "id": "Qj4Xdeu4eQ-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wget\n",
        "\n",
        "site_url = \"https://en.wikipedia.org/wiki/Python_(programming_language)\"\n",
        "\n",
        "file_name = wget.download(site_url, \"file.txt\")\n",
        "print(site_url)"
      ],
      "metadata": {
        "id": "iw0LHyk9fhzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eZ12bZKb2eDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Summarising (Review)\n",
        "1. Installing Hugging Face Transformers\n",
        "2. Building a summarisation pipeline\n",
        "3. Run model/pipeline to summarisation\n",
        "4. Investigate way to reuse the pipeline\n",
        "> [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) free state-of-the-art pre-trained machine learning models for processing text, images, audio and video. See the project website for more information.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FHtmW79E_jJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Dependencies\n",
        "!pip install transformers -q"
      ],
      "metadata": {
        "id": "Ha0NwuodI4Gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's make it a function - A function that take an 'article' and returns a summary"
      ],
      "metadata": {
        "id": "F1MWA01cL142"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from transformers import pipeline\n",
        "\n",
        "def summarise(article):\n",
        "  summary_pipeline = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\") # load sumarisation pipeline \n",
        "  summary = summary_pipeline(article, max_length = 100, min_length= 50) # Run the summariser pipeline\n",
        "  text = summary[0]['summary_text'] # Extract the summarised text --- get first element, then extract the value for key 'summary text'\n",
        "  return text\n",
        "  "
      ],
      "metadata": {
        "id": "WW424_LrLwEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#call the summarise function\n"
      ],
      "metadata": {
        "id": "8ZaKqtWeMVyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting PDF using PyMuPDF (review)\n",
        "\n",
        "Refer to text_summerizer notebook for the steps"
      ],
      "metadata": {
        "id": "BO51cJoJOtFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the PDF file\n",
        "!wget https://link.springer.com/content/pdf/10.1007/s11306-019-1588-0.pdf"
      ],
      "metadata": {
        "id": "U2_dmnPNO5IE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF"
      ],
      "metadata": {
        "id": "zsD5717PO69w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract text from pdf\n",
        "\n",
        "import fitz  # this is pymupdf\n",
        "\n",
        "file_name = \"/content/s11306-019-1588-0.pdf\"\n",
        "\n",
        "with fitz.open(file_name) as doc:\n",
        "    text = \"\"\n",
        "    for page in doc:        \n",
        "        text += page.get_text(\"text\")\n",
        "\n",
        "#print(text)"
      ],
      "metadata": {
        "id": "r_D9n_GYPItA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#summarizer pipeline have limit to 1024 words\n",
        "pprint(summarise(text[:1000])) # calling the def summarise(article) function"
      ],
      "metadata": {
        "id": "7OufJ97fa-eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cx77wSJ73Uye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Web Scraping & text summarisation\n",
        "\n",
        "## Scrape text from webpage and summarise text.\n",
        "Lets use the pipeline to summarise a web page. \n",
        "\n",
        "Google search and after looking at a few online articles, YouTube videos I settled on this page: [2 Ways to Extract Text From HTML Using Python](https://computersciencehub.io/python/extract-text-from-html-using-python/)\n",
        "\n",
        "https://computersciencehub.io/python/extract-text-from-html-using-python/\n",
        "\n",
        "https://www.geeksforgeeks.org/implementing-web-scraping-python-beautiful-soup/\n",
        "\n",
        "https://www.edureka.co/blog/web-scraping-with-python/"
      ],
      "metadata": {
        "id": "VdOrtHh1oSpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import Request, urlopen\n",
        "\n",
        "# get webpage\n",
        "req = Request(\"https://en.wikipedia.org/wiki/Python_(programming_language)\")\n",
        "html_page = urlopen(req)\n",
        "\n",
        "soup = BeautifulSoup(html_page, features=\"html.parser\")\n",
        "\n",
        "# remove all 'script' and 'style' elements\n",
        "for script in soup([\"script\", \"style\"]):\n",
        "    script.extract()    # rip it out\n",
        "\n",
        "# get text\n",
        "text = soup.get_text()\n",
        "\n",
        "pprint(text)\n",
        "print('\\n\\n\\n')\n",
        "\n",
        "# break into lines and remove leading and trailing space on each\n",
        "lines =  text.splitlines()\n",
        "\n",
        "# remove empty lines\n",
        "lines = [x for x in lines if x]\n",
        "\n",
        "# combine into one body of text\n",
        "text = ' '.join(lines)\n",
        "# split into words\n",
        "text = text.split()\n",
        "# get first 400 words\n",
        "#text = text[:400]\n",
        "# join words into text\n",
        "text = ' '.join(text)\n",
        "\n",
        "\n",
        "pprint(text)"
      ],
      "metadata": {
        "id": "XMpiTNGgeQUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(summarise(text[:1000])) # calling the def summarise(article) function"
      ],
      "metadata": {
        "id": "AYfxENQecN_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's make it a function."
      ],
      "metadata": {
        "id": "iYRUaFaWyxky"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pyXedLQyim88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h00BMO0My40K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}