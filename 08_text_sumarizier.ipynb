{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seelisher/ISYS5002_Yixiao-Li_20526379_Homework/blob/main/08_text_sumarizier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Summarisation\n",
        "\n",
        "There’s sooo much content to take in these days. \n",
        "\n",
        "* Blog posts\n",
        "* YouTube\n",
        "* Podcasts\n",
        "* Reports\n",
        "\n",
        "Wouldn't it be great to be able to summarise \n",
        "\n",
        "Using Hugging Face Transformers you can leverage a pre-trained summarisation pipeline to start summarising content.\n",
        "\n",
        "In this notebook you'll go through: \n",
        "1. Installing Hugging Face Transformers\n",
        "2. Building a summarization pipeline\n",
        "3. Running an encoding decoding model for summarization\n",
        "\n",
        "\n",
        "# Task\n",
        "\n",
        "We will write a notebook to convert a PDF or Word document to text or Web pages to text. The strategy is to convert everything to text and then summarise the text.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SmVEXRTA1wZn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Summarizing text\n",
        "1. Installing Hugging Face Transformers\n",
        "2. Building a summarization pipeline\n",
        "3. Run model/pipeline to summarisation\n",
        "4. [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) free state-of-the-art pre-trained machine learning models for processing text, images, audio and video. See the project website for more information.\n",
        "\n",
        "AI Text Summarization with Hugging Face Transformers in 4 Lines of Python: \n",
        "https://www.youtube.com/watch?v=TsfLm5iiYb4"
      ],
      "metadata": {
        "id": "FHtmW79E_jJS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Install Hugging Face Transformers and Import Dependencies"
      ],
      "metadata": {
        "id": "VA5FyTIOmSyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "6VaWKTfymjoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import dependecies\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "w5by8iL6n3Ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Build a pipeline and pass through text\n",
        "Load the pre-trained 'Summarization' from Pipeline"
      ],
      "metadata": {
        "id": "Aq6uBBitmaXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline('summarization')"
      ],
      "metadata": {
        "id": "4EYAYJqhmkQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(summarizer)"
      ],
      "metadata": {
        "id": "3h89s64frjgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Summarize Text"
      ],
      "metadata": {
        "id": "pqP63GnEmf0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "article = \"\"\"\n",
        "Around the world, as regulators look to rein in Big Tech, like the ongoing digital platforms inquiry in Australia, online platforms will face a raft of new rules in the EU.\n",
        "Known as the Digital Services Act, it’s a comprehensive set of regulations for digital services and content in the Eurozone.\n",
        "Like GDPR, the Digital Services Act is expected to lead the way for other countries to provide some rules around how digital services function, \n",
        "with everything from algorithms to online marketplaces, social networks, content-sharing platforms, app stores and online travel and accommodation platforms included.\n",
        "The Digital Services Act sets out clear due diligence obligations for digital platforms and other online intermediaries with measures for cooperation with trusted flaggers and \n",
        "competent authorities on content moderation, and measures to deter rogue traders from reaching consumers.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "48RNuGBQIHQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer(article, min_length=25, max_length=100)"
      ],
      "metadata": {
        "id": "PV4XVv2r-_fA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = summarizer(article, min_length=25, max_length=100)"
      ],
      "metadata": {
        "id": "ipv7UdqRcmBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary[0]['summary_text']"
      ],
      "metadata": {
        "id": "DYpTLpKEcqFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary[0]['summary_text'].split('.')"
      ],
      "metadata": {
        "id": "qYr5o3C0dBF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "adHCzKQWt00i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Summarise PDF using PyMuPDF"
      ],
      "metadata": {
        "id": "c8wd_jI48SHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget"
      ],
      "metadata": {
        "id": "6ijHMepx__g6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download a pdf file"
      ],
      "metadata": {
        "id": "0DHBSr_AsX0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Scholar 'Toward collaborative open data science in metabolomics using Jupyter Notebooks and cloud computing'\n",
        "!wget https://link.springer.com/content/pdf/10.1007/s11306-019-1588-0.pdf"
      ],
      "metadata": {
        "id": "Q22ZQqr6Q7Ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OR"
      ],
      "metadata": {
        "id": "aHEHtijvsUgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wget\n",
        "\n",
        "site_url = 'https://link.springer.com/content/pdf/10.1007/s11306-019-1588-0.pdf'\n",
        "file_name = wget.download(site_url)\n",
        "print(file_name)"
      ],
      "metadata": {
        "id": "EkJ28SYuMclv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF"
      ],
      "metadata": {
        "id": "msDeWTineRGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz # this is Pymupdf\n",
        "\n",
        "with fitz.open(file_name) as doc:\n",
        "  text = \"\"\n",
        "  for page in doc:\n",
        "    text = text + page.get_text()\n",
        "    \n",
        "print(text)"
      ],
      "metadata": {
        "id": "qaXAc_SQeZnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_summary = summarizer(text[:1024], min_length =100, max_length=250)\n",
        "pdf_summary"
      ],
      "metadata": {
        "id": "YgIkX3aafZeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Summarise Webpage\n",
        "\n",
        "\n",
        "https://www.geeksforgeeks.org/implementing-web-scraping-python-beautiful-soup/\n",
        "\n"
      ],
      "metadata": {
        "id": "E7c-hpWGMjUc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NqvjK_TmMqkT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}